{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1703087113578,
     "user": {
      "displayName": "Muqeem Mahmood",
      "userId": "09759898431620468120"
     },
     "user_tz": -300
    },
    "id": "V9n41Ewf4ptR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Specifying path for policy table\n",
    "file_path = 'phase_1_policy.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1703087116454,
     "user": {
      "displayName": "Muqeem Mahmood",
      "userId": "09759898431620468120"
     },
     "user_tz": -300
    },
    "id": "yU_Vlp0A4ptX"
   },
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = [0 for _ in range(9)]\n",
    "        self.current_player = -1\n",
    "\n",
    "    def print_board(self):\n",
    "        for i in range(0, 9, 3):\n",
    "\n",
    "            print(str(self.board[i]) + \"|\" + str(self.board[i + 1]) + \"|\" + str(self.board[i + 2]))\n",
    "            if i < 6:\n",
    "                print(\"-\" * 5)\n",
    "\n",
    "        print()\n",
    "\n",
    "    def check_win(self, player):\n",
    "        win_conditions = [(0, 1, 2), (3, 4, 5), (6, 7, 8),\n",
    "                        (0, 3, 6), (1, 4, 7), (2, 5, 8),\n",
    "                        (0, 4, 8), (2, 4, 6)]\n",
    "\n",
    "        for condition in win_conditions:\n",
    "            if all(self.board[i] == player for i in condition):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def step(self, position):\n",
    "        if self.board[position] == 0:\n",
    "            self.board[position] = self.current_player\n",
    "            if self.check_win(self.current_player):\n",
    "                return self.board, self.current_player, True\n",
    "            elif 0 not in self.board:\n",
    "                return self.board, 0, True\n",
    "            self.current_player = 1 if self.current_player == -1 else -1\n",
    "            return self.board, self.current_player, False\n",
    "        else:\n",
    "            print(\"Cell already occupied. Try again.\")\n",
    "            return self.board, self.current_player, False\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1703088393110,
     "user": {
      "displayName": "Muqeem Mahmood",
      "userId": "09759898431620468120"
     },
     "user_tz": -300
    },
    "id": "Xcte2OrT4ptY"
   },
   "outputs": [],
   "source": [
    "# This cell defines all the helper functions needed for this environment\n",
    "win_conditions = [(0, 1, 2), (3, 4, 5), (6, 7, 8), (0, 3, 6), (1, 4, 7), (2, 5, 8), (0, 4, 8), (2, 4, 6)]\n",
    "\n",
    "def generate_state_space(steps):\n",
    "    \"\"\"\n",
    "    Generates the state space of a 2d tic-tac-toe.\n",
    "    1) Iterates over each stage of the game assuming \"Player -1\" starts first\n",
    "    2) Alternates between \"Player -1 and \"Player +1\" for each stage\n",
    "    3) Avoids invalid states by skipping the iterations for a state meeting terminal states requirements\n",
    "    4) Removes duplicates by including only the unique states present at each stage\n",
    "    5) Returns a list of arrays correspoinding to each stage (shape = (9,))\n",
    "    \"\"\"\n",
    "    state_space = []\n",
    "\n",
    "    state_space.append(np.array([0 for _ in range(steps)]))\n",
    "\n",
    "    for j in range(steps):\n",
    "        if j == 0:\n",
    "            curr_action = -1\n",
    "            step_state = []\n",
    "            for i in range(steps):\n",
    "                step = [0 for _ in range(steps)]\n",
    "                step[i] = curr_action\n",
    "                step_state.append(step)\n",
    "            step_state = np.array(step_state)\n",
    "        else:\n",
    "            step_state = []\n",
    "            curr_action = -1 * prev_action\n",
    "            for i in range(len(prev_step_state)):\n",
    "                step_temp = []\n",
    "                for k in range(steps):\n",
    "                    state = copy.deepcopy(prev_step_state[i])\n",
    "                    if win_state(state, prev_action):\n",
    "                        continue\n",
    "                    if state[k] == -1 or state[k] == 1:\n",
    "                        continue\n",
    "                    state[k] = curr_action\n",
    "                    step_temp.append(state)\n",
    "                if not step_temp:\n",
    "                    continue\n",
    "                else:\n",
    "                    step_state.append(step_temp)\n",
    "            shape = np.shape(step_state)\n",
    "            step_state = np.array(step_state).reshape(shape[0] * shape[1], shape[2])\n",
    "            step_state = np.unique(step_state, axis=0)\n",
    "\n",
    "        state_space.append(step_state)\n",
    "        prev_action = curr_action\n",
    "        prev_step_state = copy.deepcopy(step_state)\n",
    "\n",
    "    return state_space\n",
    "\n",
    "def get_value_table(num_states, total_state_space, terminal_states, gamma):\n",
    "    \"\"\"\n",
    "    Runs value iterations for the 2d tic-tac-toe.\n",
    "    1) Avoids updating terminal states\n",
    "    2) Assumes the system is deterministic\n",
    "    3) Returns a value table corresponding to the value of each state in state space\n",
    "    \"\"\"\n",
    "    value_table = np.zeros(num_states)\n",
    "\n",
    "    for j in range(100):\n",
    "\n",
    "        state_space = copy.deepcopy(total_state_space)\n",
    "\n",
    "        for i, state in enumerate(state_space):\n",
    "\n",
    "            if not np.any(np.all(state == terminal_states, axis=1)):\n",
    "\n",
    "                action, position = get_possible_actions(state)\n",
    "                update_values = []\n",
    "\n",
    "                for pos in position:\n",
    "                    next_state = find_next_state(state, action, pos)\n",
    "                    next_state_idx = find_next_state_index(next_state, state_space)\n",
    "                    value = get_reward(next_state, action) + gamma * value_table[next_state_idx]\n",
    "                    update_values.append(value)\n",
    "\n",
    "                if action == -1:\n",
    "                    value_table[i] = min(update_values)\n",
    "                elif action == 1:\n",
    "                    value_table[i] = max(update_values)\n",
    "\n",
    "    return value_table\n",
    "\n",
    "def get_policy(state_space, terminal_states, value_table, gamma):\n",
    "    \"\"\"\n",
    "    Returns the optimal policy for the state space.\n",
    "    1) optimal policy is a list containing the state, action value, and the position of the value to be placed\n",
    "    \"\"\"\n",
    "\n",
    "    policy_table = []\n",
    "\n",
    "    for state in state_space:\n",
    "\n",
    "        if not np.any(np.all(state == terminal_states, axis=1)):\n",
    "\n",
    "            action, position = get_possible_actions(state)\n",
    "            values = []\n",
    "\n",
    "            for pos in position:\n",
    "                next_state = find_next_state(state, action, pos)\n",
    "                next_state_idx = find_next_state_index(next_state, state_space)\n",
    "                value = get_reward(next_state, action) + gamma * value_table[next_state_idx]\n",
    "                values.append(value)\n",
    "\n",
    "            if action == -1:\n",
    "                idx = values.index(min(values))\n",
    "            elif action == 1:\n",
    "                idx = values.index(max(values))\n",
    "\n",
    "            opt_pos = position[idx]\n",
    "            opt_action = [state.tolist(), int(action), int(opt_pos)]\n",
    "\n",
    "            policy_table.append(opt_action)\n",
    "\n",
    "        else:\n",
    "\n",
    "            policy_table.append([state.tolist(), int(0), int(0)])\n",
    "\n",
    "    return policy_table\n",
    "\n",
    "def win_state(state, action):\n",
    "    \"\"\"\n",
    "    Checks for the win condition of a state-action pair.\n",
    "    1) Takes a state and the corresponding action as an argument\n",
    "    2) Checks for each condition in the win_conditions\n",
    "    3) Returns a boolean \"True\" if any one of the win_conditions is met and vice versa\n",
    "    \"\"\"\n",
    "    win = False\n",
    "    for condition in win_conditions:\n",
    "        if all(state[i] == action for i in condition):\n",
    "            win = True\n",
    "            break\n",
    "    return win\n",
    "\n",
    "def get_reward(state, action):\n",
    "    \"\"\"\n",
    "    Returns a reward for the corresponding state-action pair.\n",
    "    1) Takes a state and the corresponding action as an argument\n",
    "    2) Returns -1 (for player 1) or +1 (for player 2) if the state-action pair meets the win_condition. Returns 0 otherwise\n",
    "    \"\"\"\n",
    "    reward = 0\n",
    "    if win_state(state, action):\n",
    "        reward = action\n",
    "    return reward\n",
    "\n",
    "def find_next_state_index(state, ss):\n",
    "    \"\"\"\n",
    "    Returns the row index of a state from the state space.\n",
    "    1) Takes state and state space \"ss\" as an argument\n",
    "    2) Returns the row index\n",
    "    \"\"\"\n",
    "    index = np.where(np.all(state == ss, axis=1))[0][0]\n",
    "    return index\n",
    "\n",
    "def get_possible_actions(state):\n",
    "    \"\"\"\n",
    "    Returns the possible value of action and its valid positions for a given state.\n",
    "    1) Takes a state as an argument\n",
    "    2) Sets a possible action and its applicable positions in the state\n",
    "    3) Returns an action and a list of positions\n",
    "    \"\"\"\n",
    "    if np.count_nonzero(state == -1) <= np.count_nonzero(state == 1):\n",
    "        action = -1\n",
    "    elif np.count_nonzero(state == 1) < np.count_nonzero(state == -1):\n",
    "        action = 1\n",
    "    position = np.where(state == 0)[0]\n",
    "    return action, position\n",
    "\n",
    "def find_next_state(state, action, pos):\n",
    "    \"\"\"\n",
    "    Finds the next state to a corresponding state-action pair.\n",
    "    1) Takes state, action value, and the position to be applied as an argument\n",
    "    2) Returns the next state after applying the action on the corresponding state\n",
    "    \"\"\"\n",
    "    s = copy.deepcopy(state)\n",
    "    s[pos] = action\n",
    "    return s\n",
    "\n",
    "def get_terminal_states(ss):\n",
    "    \"\"\"\n",
    "    Finds the terminal states of the state space.\n",
    "    1) Take state space as an argument\n",
    "    2) Checks for the state-wise win condtion for all stages except the last stage and appends it in the terminal stages\n",
    "    3) Appends every state in the last stage into the terminal states\n",
    "    4) Returns a numpy array of terminal states\n",
    "    \"\"\"\n",
    "    terminal_states = []\n",
    "\n",
    "    for i, stage_state_space in enumerate(ss):\n",
    "        if i == 0:\n",
    "            if (win_state(stage_state_space, -1) or win_state(stage_state_space, 1)):\n",
    "                  terminal_states.append(stage_state_space)\n",
    "        else:\n",
    "            for state in stage_state_space:\n",
    "                if (win_state(state, -1) or win_state(state, 1)) and i != 9:\n",
    "                    terminal_states.append(state)\n",
    "                if i == 9:\n",
    "                    terminal_states.append(state)\n",
    "\n",
    "    return np.array(terminal_states)\n",
    "\n",
    "def get_position(state, policy_table):\n",
    "    \"\"\"\n",
    "    Returns the optimum position for the player from the policy table\n",
    "    \"\"\"\n",
    "    for x in policy_table:\n",
    "        if np.array_equal(x[0], state):\n",
    "            pos = x[2]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 394791,
     "status": "ok",
     "timestamp": 1703088793997,
     "user": {
      "displayName": "Muqeem Mahmood",
      "userId": "09759898431620468120"
     },
     "user_tz": -300
    },
    "id": "s1_Y-UHZ4pta"
   },
   "outputs": [],
   "source": [
    "# This cell computes the state space, value table, and policy table for this problem\n",
    "\n",
    "ss = generate_state_space(9)\n",
    "total_state_space = np.vstack(ss)\n",
    "num_states = np.shape(total_state_space)[0]\n",
    "\n",
    "terminal_states = get_terminal_states(ss)\n",
    "gamma = 0.99\n",
    "\n",
    "value_table = get_value_table(num_states, total_state_space, terminal_states, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3573,
     "status": "ok",
     "timestamp": 1703088976832,
     "user": {
      "displayName": "Muqeem Mahmood",
      "userId": "09759898431620468120"
     },
     "user_tz": -300
    },
    "id": "2pA6jWKV4ptb"
   },
   "outputs": [],
   "source": [
    "# This cell computes the policy for each state\n",
    "policy = get_policy(total_state_space, terminal_states, value_table, gamma)\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(policy, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1703089116473,
     "user": {
      "displayName": "Muqeem Mahmood",
      "userId": "09759898431620468120"
     },
     "user_tz": -300
    },
    "id": "i-lgUUDz4ptb",
    "outputId": "e8d38751-7b14-4af4-f0c9-73fa0a4124e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draws: 1000\n",
      "Player 1 wins: 0\n",
      "Player 2 wins: 0\n"
     ]
    }
   ],
   "source": [
    "env = TicTacToe()\n",
    "terminated = False\n",
    "player_1_wins = 0\n",
    "player_2_wins = 0\n",
    "draws = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    if terminated:\n",
    "        env.reset()\n",
    "    while True:\n",
    "        position = get_position(env.board, policy)\n",
    "\n",
    "        board, player, terminated = env.step(position)\n",
    "\n",
    "        if terminated:\n",
    "            if player == -1:\n",
    "                player_1_wins += 1\n",
    "            elif player == 1:\n",
    "                player_2_wins += 1\n",
    "            elif player == 0:\n",
    "                draws += 1\n",
    "            break\n",
    "            \n",
    "print(f\"Draws: {draws}\")\n",
    "print(f\"Player 1 wins: {player_1_wins}\")\n",
    "print(f\"Player 2 wins: {player_2_wins}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
